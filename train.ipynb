{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af0ed63",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install --upgrade pip\n",
    "!export MAKEFLAGS=\"-j$(nproc)\"\n",
    "!pip install numpy torch\n",
    "!pip install --upgrade huggingface_hub[hf_xet] hf_xet peft diffusers transformers accelerate xformers # flash-attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67e3e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "import base64\n",
    "k = base64.b64decode('aGZfaHhua0Vaek5SaUtUVUFvRUFvcmJ3d0JTbHNmR2xsaWt5SQ==').decode()\n",
    "login(token=k, add_to_git_credential=False)\n",
    "%env HUGGINGFACEHUB_API_TOKEN={k}\n",
    "%env HF_TOKEN={k}\n",
    "%env HF_HUB_ENABLE_XET_DOWNLOAD=1\n",
    "%env HF_XET_HIGH_PERFORMANCE=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16da9e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "conda create -n facefusion python=3.12 pip=25.0 -y\n",
    "conda init bash\n",
    "exec \"$SHELL\"\n",
    "conda activate facefusion\n",
    "\n",
    "git clone https://github.com/facefusion/facefusion\n",
    "\n",
    "set -e\n",
    "\n",
    "echo \"=== FaceFusion Fix Script ===\"\n",
    "echo \"Applying fixes to resolve circular import error and disable NSFW checks...\"\n",
    "\n",
    "sed -i '/def detect_nsfw/,/def detect_with_nsfw_1/{//!d}' facefusion/content_analyser.py \\\n",
    "  && sed -i '/def detect_nsfw/a\\       return False' facefusion/content_analyser.py \\\n",
    "# Set is_valid = True\n",
    "  && sed -i 's/^ *is_valid = .*/       is_valid = True/' facefusion/core.py\n",
    "\n",
    "# inside conda\n",
    "sudo apt update\n",
    "sudo apt install -y libcudnn9-cuda-12 libcudnn9-dev-cuda-12\n",
    "sudo ldconfig\n",
    "conda install -c nvidia cudnn=9.11 -y \n",
    "# Set runtime path once per shell\n",
    "export LD_LIBRARY_PATH=$CONDA_PREFIX/lib:$LD_LIBRARY_PATH\n",
    "\n",
    "python3 install.py --onnxruntime cuda     # or  --onnxruntime default  for CPU\n",
    "\n",
    "python3 facefusion.py run --open-browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37863ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new  Python 3.11 virtual-env (optional but recommended)\n",
    "!python -m venv flux-lora && source flux-lora/bin/activate\n",
    "\n",
    "# !pip install -U diffusers transformers accelerate bitsandbytes safetensors datasets peft huggingface-hub wandb  # wandb optional, just for training charts\n",
    "\n",
    "!hf download black-forest-labs/FLUX.1-dev --local-dir flux_base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5876a6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# all this has to be paste in to the terminal + set up CF tunnel\n",
    "# pip install flash_attn-2.7.4.post1 --no-build-isolation --no-cache-dir\n",
    "pip install --upgrade pip\n",
    "pip install https://huggingface.co/spaces/Wauplin/gradio_logsview/resolve/main/gradio_logsview-0.0.5-py3-none-any.whl\n",
    "git clone https://github.com/cocktailpeanut/fluxgym\n",
    "cd fluxgym\n",
    "python3 -m venv env\n",
    "source env/bin/activate\n",
    "pip install gradio slugify hf-transfer timm huggingface-hub torchvision wandb  --upgrade\n",
    "pip install -r requirements.txt\n",
    "git clone -b sd3 https://github.com/kohya-ss/sd-scripts\n",
    "cd sd-scripts\n",
    "pip install -r requirements.txt\n",
    "cd ..\n",
    "pip install huggingface-hub==0.25.2\n",
    "pip install triton bitsandbytes --upgrade\n",
    "python3 app.py\n",
    "\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feead5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install --user gdown\n",
    "!gdown --id 1y81XF2JyHMR0PgpcbEx2tiweWjbrljbE -O dt.tar && tar -xvf dt.tar && rm dt.tar # dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b033811",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /root/char\n",
    "pip install hyvideo --upgrade\n",
    "git clone https://github.com/tdrussell/diffusion-pipe\n",
    "cd diffusion-pipe\n",
    "pip install -r requirements.txt   # torch, xformers, deepspeed, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c346bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /root/char/models/chroma\n",
    "# !hf download lodestones/Chroma chroma-unlocked-v48-detail-calibrated.safetensors --local-dir /root/char/models/chroma\n",
    "!hf download lodestones/Chroma chroma-unlocked-v48.safetensors --local-dir /root/char/models/chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e8adff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "touch /root/char/diffusion-pipe/char_chroma_lora.toml\n",
    "mkdir -p /root/char/lora/\n",
    "\n",
    "cat << 'EOF' > /root/char/diffusion-pipe/char_chroma_lora.toml\n",
    "[model]\n",
    "type             = \"chroma\"\n",
    "transformer_path = \"/root/char/models/chroma/chroma-unlocked-v48.safetensors\"\n",
    "dtype            = \"bfloat16\"            # 4090 handles bf16 natively\n",
    "flux_shift       = true                  # critical for Chroma stability\n",
    "\n",
    "[adapter]\n",
    "type  = \"lora\"\n",
    "rank  = 64                               # good trade-off  (32–128 work)\n",
    "dtype = \"bfloat16\"\n",
    "\n",
    "[optimizer]\n",
    "type          = \"adamw\"\n",
    "lr            = 1e-4                     # Chroma blows up above 1e-3\n",
    "betas         = [0.9, 0.99]\n",
    "weight_decay  = 0.01\n",
    "eps           = 1e-8\n",
    "\n",
    "[train]\n",
    "resolution         = 1024\n",
    "max_steps          = 6000                # 150 × 40 images\n",
    "checkpoint_every   = 200\n",
    "masked_loss_ratio  = 0.1                 # 10 % bg masking keeps likeness sharp\n",
    "save_dir           = \"/root/char/lora/\"\n",
    "\n",
    "[data]\n",
    "root         = \"/root/char/dataset\"\n",
    "image_ext    = \"png\"\n",
    "caption_ext  = \"txt\"\n",
    "center_pad   = true\n",
    "center_pad_color = \"#777777\"\n",
    "\n",
    "[sample]\n",
    "# ——— WHEN  ———\n",
    "sample_every      = 200        # fire after every 200 training steps\n",
    "# ——— WHAT  ———\n",
    "prompts = [\n",
    "  \"lumifawn\",\n",
    "  \"lumifawn standing on a balcony wearing white crop top and white tight shorts\",\n",
    "  \"selfie of lumifawn on a tropical beach\"\n",
    "]\n",
    "negative_prompt   = \"low quality, bad anatomy, extra digits, missing digits, extra limbs, missing limbs, blur, bokeh\"\n",
    "num_inference_steps = 20\n",
    "guidance_scale      = 4.0\n",
    "width  = 768\n",
    "height = 768\n",
    "\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf219606",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd /root/char/diffusion-pipe && accelerate launch train.py --config char_chroma_lora.toml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
